import subprocess
import json
import argparse
import glob
import os

def process_line(line):
    try:
        data = json.loads(line)
        # Replace 'your_key' with the specific key you want to extract
        value = data.get('your_key')
        if value is not None:
            print(f"Extracted value: {value}")
    except json.JSONDecodeError:
        # Ignore lines that are not in JSON format
        pass

def read_log_file(file_path, num_lines):
    # Use subprocess to call the 'tail' command to read the last N lines
    tail_process = subprocess.Popen(['tail', '-n', str(num_lines), '-F', file_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

    try:
        while True:
            line = tail_process.stdout.readline().strip()
            if line:
                # Add your custom patterns to filter lines here
                if 'your_pattern' in line:
                    process_line(line)
    except KeyboardInterrupt:
        # Handle Ctrl+C to gracefully exit the script
        pass
    finally:
        tail_process.kill()

def find_latest_matching_file():
    base_path = '/path/to/your/download_directory'
    file_pattern = '*.log'
    files = glob.glob(os.path.join(base_path, file_pattern))
    if not files:
        raise FileNotFoundError(f"No matching files found in directory: {base_path}")

    latest_file = max(files, key=os.path.getctime)
    return latest_file

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Read and process JSON log file.")
    parser.add_argument("--num_lines", type=int, default=10, help="Number of last lines to read initially")
    args = parser.parse_args()

    latest_log_file = find_latest_matching_file()
    print(f"Using the latest log file: {latest_log_file}")

    read_log_file(latest_log_file, args.num_lines)
