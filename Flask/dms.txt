1234567890.12345678901234567890
2345678901.23456789012345678901
3456789012.34567890123456789012
4567890123.45678901234567890123


rdd = sc.textFile("sample_data.txt")

df = rdd.toDF(["decimal_numbers"])

df.show()

from pyspark.sql.types import StructType, StructField, DecimalType

# define the schema for the DataFrame
schema = StructType([
    StructField("decimal_numbers", DecimalType(30, 20))
])

# read the text file and create an RDD
rdd = sc.textFile("sample_data.txt")

# convert the RDD to a DataFrame using the custom schema
df = spark.read.schema(schema).csv(rdd.map(lambda x: (x,)), header=False)

# print the DataFrame to check the precision values
df.show()

# read the text file and create a DataFrame
df = spark.read.text("sample_data.txt")

# print the DataFrame to check the data types and precision values
df.show()
