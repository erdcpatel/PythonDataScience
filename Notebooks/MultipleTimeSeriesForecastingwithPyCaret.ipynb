{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6992ebb",
   "metadata": {},
   "source": [
    "## Multiple Time Series Forecasting with PyCaret\n",
    "https://pycaret.gitbook.io/docs/learn-pycaret/official-blog/multiple-time-series-forecasting-with-pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "import pandas as pd\n",
    "data = pd.read_csv('/Users/Dhaval/Downloads/train.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "# combine store and item column as time_series\n",
    "data['store'] = ['store_' + str(i) for i in data['store']]\n",
    "data['item'] = ['item_' + str(i) for i in data['item']]\n",
    "data['time_series'] = data[['store', 'item']].apply(lambda x: '_'.join(x), axis=1)\n",
    "data.drop(['store', 'item'], axis=1, inplace=True)\n",
    "# extract features from date\n",
    "data['month'] = [i.month for i in data['date']]\n",
    "data['year'] = [i.year for i in data['date']]\n",
    "data['day_of_week'] = [i.dayofweek for i in data['date']]\n",
    "data['day_of_year'] = [i.dayofyear for i in data['date']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f16fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique time_series\n",
    "data['time_series'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62375cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot multiple time series with moving avgs in a loop**\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "for i in data['time_series'].unique():\n",
    "    subset = data[data['time_series'] == i]\n",
    "    subset['moving_average'] = subset['sales'].rolling(30).mean()\n",
    "    fig = px.line(subset, x=\"date\", y=[\"sales\",\"moving_average\"], title = i, template = 'plotly_dark')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pycaret.regression import *\n",
    "\n",
    "all_ts = data['time_series'].unique()\n",
    "\n",
    "all_results = []\n",
    "final_model = {}\n",
    "\n",
    "for i in tqdm(all_ts):\n",
    "    \n",
    "    df_subset = data[data['time_series'] == i]\n",
    "    \n",
    "    # initialize setup from pycaret.regression\n",
    "    s = setup(df_subset, target = 'sales', train_size = 0.95,\n",
    "              data_split_shuffle = False, fold_strategy = 'timeseries', fold = 3,\n",
    "              ignore_features = ['date', 'time_series'],\n",
    "              numeric_features = ['day_of_year', 'year'],\n",
    "              categorical_features = ['month', 'day_of_week'],\n",
    "              silent = True, verbose = False, session_id = 123)\n",
    "    \n",
    "    # compare all models and select best one based on MAE\n",
    "    best_model = compare_models(sort = 'MAE', verbose=False)\n",
    "    \n",
    "    # capture the compare result grid and store best model in list\n",
    "    p = pull().iloc[0:1]\n",
    "    p['time_series'] = str(i)\n",
    "    all_results.append(p)\n",
    "    \n",
    "    # finalize model i.e. fit on entire data including test set\n",
    "    f = finalize_model(best_model)\n",
    "    \n",
    "    # attach final model to a dictionary\n",
    "    final_model[i] = f\n",
    "    \n",
    "    # save transformation pipeline and model as pickle file \n",
    "    save_model(f, model_name='trained_models/' + str(i), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e7f1b",
   "metadata": {},
   "source": [
    "We can now create a data frame from all_results list. It will display the best model selected for each time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7145f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results = pd.concat(all_results,axis=0)\n",
    "concat_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d89c3b",
   "metadata": {},
   "source": [
    "### Generate predictions using trained models\n",
    "Now that we have trained models, let’s use them to generate predictions, but first, we need to create the dataset for scoring (X variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a date range from 2013 to 2019\n",
    "all_dates = pd.date_range(start='2013-01-01', end = '2019-12-31', freq = 'D')\n",
    "# create empty dataframe\n",
    "score_df = pd.DataFrame()\n",
    "# add columns to dataset\n",
    "score_df['date'] = all_dates\n",
    "score_df['month'] = [i.month for i in score_df['date']]\n",
    "score_df['year'] = [i.year for i in score_df['date']]\n",
    "score_df['day_of_week'] = [i.dayofweek for i in score_df['date']]\n",
    "score_df['day_of_year'] = [i.dayofyear for i in score_df['date']]\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20271e8",
   "metadata": {},
   "source": [
    "Now let’s create a loop to load the trained pipelines and use the `predict_model` function to generate prediction labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import load_model, predict_model\n",
    "all_score_df = []\n",
    "for i in tqdm(data['time_series'].unique()):\n",
    "    l = load_model('trained_models/' + str(i), verbose=False)\n",
    "    p = predict_model(l, data=score_df)\n",
    "    p['time_series'] = i\n",
    "    all_score_df.append(p)\n",
    "concat_df = pd.concat(all_score_df, axis=0)\n",
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca033a83",
   "metadata": {},
   "source": [
    "We will now join the `data` and `concat_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(concat_df, data, how = 'left', left_on=['date', 'time_series'], right_on = ['date', 'time_series'])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2282ef",
   "metadata": {},
   "source": [
    "We can now create a loop to see all plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ba829",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_df['time_series'].unique()[:5]:\n",
    "    sub_df = final_df[final_df['time_series'] == i]\n",
    "    \n",
    "    import plotly.express as px\n",
    "    fig = px.line(sub_df, x=\"date\", y=['sales', 'Label'], title=i, template = 'plotly_dark')\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
